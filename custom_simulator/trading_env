# Most of this file is copied from https://github.com/AI4Finance-Foundation/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020
class StockEnvTrade(gym.Env):
    """A stock trading environment for OpenAI gym"""
    metadata = {'render.modes': ['human']}

    def __init__(self, df, day=0, turbulence_threshold=None, initial=True, previous_state=[], model_name='', iteration=''):
        #super(StockEnvTrade, self).__init__()
        # money = 10 , scope = 1
        self.day = day
        self.df = df
        self.initial = initial
        self.previous_state = previous_state
        # action_space normalization and shape is STOCK_DIM
        self.action_space = spaces.Box(low=-1, high=1, shape=(STOCK_DIM,))
        # Shape = 271: [Current Balance]+[prices 1-30]+[owned shares 1-30]
        # +[macd 1-30] + [rsi 1-30] + [cci 1-30] + [adx 1-30] + [sma 1-29]
        # +[boll_ub 1-30] + [boll_lb 1-30]
        self.observation_space = spaces.Box(low=0, high=np.inf, shape=(271,))
        # load data from a pandas dataframe
        self.data = self.df.loc[self.day, :]
        self.terminal = False
        self.turbulence_threshold = turbulence_threshold
        # initalize state
        self.state = [INITIAL_ACCOUNT_BALANCE] + \
            self.data.adjust.values.tolist() + \
            [0]*STOCK_DIM + \
            self.data.macd.values.tolist() + \
            self.data.rsi.values.tolist() + \
            self.data.cci.values.tolist() + \
            self.data.adx.values.tolist() + \
            self.data.sma.values.tolist() + \
            self.data.boll_ub.values.tolist() + \
            self.data.boll_lb.values.tolist()
        # initialize reward
        self.reward = 0
        self.turbulence = 0
        self.cost = 0
        self.trades = 0
        # memorize all the total balance change
        self.asset_memory = [INITIAL_ACCOUNT_BALANCE]
        self.rewards_memory = []
        self.actions_memory = []
        self.date_memory = [self._get_date()]
        # self.reset()
        self._seed()
        self.model_name = model_name
        self.iteration = iteration

    def _sell_stock(self, index, action):
        # perform sell action based on the sign of the action
        # Sell only if the price is > 0 (no missing data in this particular date)
        if self.turbulence < self.turbulence_threshold:
            if self.state[index+STOCK_DIM+1] > 0:
              # Sell only if current asset is > 0

                sell_num_shares = min(
                    abs(action), self.state[index+STOCK_DIM+1])
                sell_amount = self.state[index+1] * \
                    sell_num_shares * (1 - TRANSACTION_FEE_PERCENT)
                # update balance
                self.state[0] += sell_amount

                self.state[index+STOCK_DIM+1] -= sell_num_shares
                self.cost += self.state[index+1] * sell_num_shares * \
                    TRANSACTION_FEE_PERCENT
                self.trades += 1
            else:
                sell_num_shares = 0
        else:
            # if turbulence goes over threshold, just clear out all positions
            if self.state[index+STOCK_DIM+1] > 0:
                # update balance
                sell_num_shares = self.state[index+STOCK_DIM+1]
                sell_amount = self.state[index+1] * \
                    sell_num_shares * (1 - TRANSACTION_FEE_PERCENT)
                self.state[0] += sell_amount
                self.state[index+STOCK_DIM+1] = 0
                self.cost += self.state[index+1]*self.state[index+STOCK_DIM+1] * \
                    TRANSACTION_FEE_PERCENT
                self.trades += 1
            else:
                sell_num_shares = 0

        return sell_num_shares

    def _buy_stock(self, index, action):
        # perform buy action based on the sign of the action
        if self.turbulence < self.turbulence_threshold:
            available_amount = self.state[0] // self.state[index+1]
            # print('available_amount:{}'.format(available_amount))

            # update balance
            buy_num_shares = min(available_amount, action)
            buy_amount = self.state[index+1] * \
                buy_num_shares * (1 + TRANSACTION_FEE_PERCENT)
            self.state[0] -= buy_amount

            self.state[index+STOCK_DIM+1] += buy_num_shares

            self.cost += self.state[index+1] * buy_num_shares * \
                TRANSACTION_FEE_PERCENT
            self.trades += 1
        else:
            # if turbulence goes over threshold, just stop buying
            buy_num_shares = 0
            pass

        return buy_num_shares

    def step(self, actions):
        # print(self.day)
        self.terminal = self.day >= len(self.df.index.unique())-1
        # print(actions)

        if self.terminal:
            plt.plot(self.asset_memory, 'r')
            plt.savefig('/content/drive/MyDrive/DRL_DataVN_sb3/results/account_value_trade_{}_{}.png'.format(
                self.model_name, self.iteration))
            plt.close()
            df_total_value = pd.DataFrame(self.asset_memory)
            #df_total_value.to_csv('/content/drive/MyDrive/DRL_DataVN_sb3/results/account_value_trade_{}_{}.csv'.format(self.model_name, self.iteration))
            end_total_asset = self.state[0] + \
                sum(np.array(self.state[1:(STOCK_DIM+1)]) *
                    np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))
            df_total_value.columns = ['account_value']
            df_total_value['Date'] = self.date_memory
            df_total_value['daily_return'] = df_total_value['account_value'].pct_change(
                1)
            sharpe = (4**0.5)*df_total_value['daily_return'].mean() / \
                df_total_value['daily_return'].std()
            print("previous_total_asset:{}".format(self.asset_memory[0]))
            print("end_total_asset:{}".format(end_total_asset))
            print("total_reward:{}".format(self.state[0]+sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(
                self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)])) - self.asset_memory[0]))
            print("total_cost: ", self.cost)
            print("total_trades: ", self.trades)
            print("Sharpe: ", sharpe)
            df_total_value.to_csv(
                '/content/drive/MyDrive/DRL_DataVN_sb3/results/account_value_trade_{}_{}.csv'.format(self.model_name, self.iteration))

            df_rewards = pd.DataFrame(self.rewards_memory)
            df_rewards.columns = ['account_rewards']
            df_rewards['Date'] = self.date_memory[:-1]
            df_rewards.to_csv(
                '/content/drive/MyDrive/DRL_DataVN_sb3/results/account_rewards_trade_{}_{}.csv'.format(self.model_name, self.iteration))

            # print('total asset: {}'.format(self.state[0]+ sum(np.array(self.state[1:29])*np.array(self.state[29:]))))
            # with open('obs.pkl', 'wb') as f:
            #    pickle.dump(self.state, f)
            df_actions = self.save_action_memory()
            df_actions.to_csv(
                '/content/drive/MyDrive/DRL_DataVN_sb3/results/actions_{}_{}.csv'.format(self.model_name, self.iteration))

            return self.state, self.reward, self.terminal, {}

        else:
            # print(np.array(self.state[1:29]))

            actions = actions * HMAX_NORMALIZE  # actions initially is scaled between 0 and 1
            # convert into integer because we can't by fraction of shares
            actions = (actions.astype(int))
            if self.turbulence >= self.turbulence_threshold:
                actions = np.array([-HMAX_NORMALIZE]*STOCK_DIM)

            begin_total_asset = self.state[0] + \
                sum(np.array(self.state[1:(STOCK_DIM+1)]) *
                    np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))
            # print("begin_total_asset:{}".format(begin_total_asset))

            argsort_actions = np.argsort(actions)

            sell_index = argsort_actions[:np.where(actions < 0)[0].shape[0]]
            buy_index = argsort_actions[::-
                                        1][:np.where(actions > 0)[0].shape[0]]

            for index in sell_index:
                #print('take sell action: {}'.format(actions[index]))
                actions[index] = self._sell_stock(index, actions[index]) * (-1)

            for index in buy_index:
                #print('take buy action: {}'.format(actions[index]))
                actions[index] = self._buy_stock(index, actions[index])

            self.actions_memory.append(actions)

            self.day += 1
            self.data = self.df.loc[self.day, :]
            self.turbulence = self.data['turbulence'].values[0]
            # print(self.turbulence)
            # load next state
            # print("stock_shares:{}".format(self.state[29:]))
            self.state = [self.state[0]] + \
                self.data.adjust.values.tolist() + \
                list(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]) + \
                self.data.macd.values.tolist() + \
                self.data.rsi.values.tolist() + \
                self.data.cci.values.tolist() + \
                self.data.adx.values.tolist() + \
                self.data.sma.values.tolist() + \
                self.data.boll_ub.values.tolist() + \
                self.data.boll_lb.values.tolist()

            end_total_asset = self.state[0] + \
                sum(np.array(self.state[1:(STOCK_DIM+1)]) *
                    np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))
            self.asset_memory.append(end_total_asset)
            # print("end_total_asset:{}".format(end_total_asset))
            self.date_memory.append(self._get_date())

            self.reward = end_total_asset - begin_total_asset
            # print("step_reward:{}".format(self.reward))
            self.rewards_memory.append(self.reward)

            self.reward = self.reward*REWARD_SCALING

        return self.state, self.reward, self.terminal, {}

    def reset(self):
        if self.initial:
            self.asset_memory = [INITIAL_ACCOUNT_BALANCE]
            self.day = 0
            self.data = self.df.loc[self.day, :]
            self.turbulence = 0
            self.cost = 0
            self.trades = 0
            self.terminal = False
            # self.iteration=self.iteration
            self.rewards_memory = []
            self.actions_memory = []
            self.date_memory = [self._get_date()]
            # initiate state
            self.state = [INITIAL_ACCOUNT_BALANCE] + \
                self.data.adjust.values.tolist() + \
                [0]*STOCK_DIM + \
                self.data.macd.values.tolist() + \
                self.data.rsi.values.tolist() + \
                self.data.cci.values.tolist() + \
                self.data.adx.values.tolist() + \
                self.data.sma.values.tolist() + \
                self.data.boll_ub.values.tolist() + \
                self.data.boll_lb.values.tolist()
        else:
            previous_total_asset = self.previous_state[0] + \
                sum(np.array(self.previous_state[1:(
                    STOCK_DIM+1)])*np.array(self.previous_state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))
            self.asset_memory = [previous_total_asset]
            #self.asset_memory = [self.previous_state[0]]
            self.day = 0
            self.data = self.df.loc[self.day, :]
            self.turbulence = 0
            self.cost = 0
            self.trades = 0
            self.terminal = False
            # self.iteration=iteration
            self.rewards_memory = []
            self.actions_memory = []
            self.date_memory = [self._get_date()]
            # initiate state
            # self.previous_state[(STOCK_DIM+1):(STOCK_DIM*2+1)]
            # [0]*STOCK_DIM + \

            self.state = [self.previous_state[0]] + \
                self.data.adjust.values.tolist() + \
                self.previous_state[(STOCK_DIM+1):(STOCK_DIM*2+1)] + \
                self.data.macd.values.tolist() + \
                self.data.rsi.values.tolist() + \
                self.data.cci.values.tolist() + \
                self.data.adx.values.tolist() + \
                self.data.sma.values.tolist() + \
                self.data.boll_ub.values.tolist() + \
                self.data.boll_lb.values.tolist()
        return self.state

    def render(self, mode='human', close=False):
        return self.state

    def _get_date(self):
        if len(self.df.Symbol.unique()) > 1:
            date = self.data.Date.unique()[0]
        else:
            date = self.data.Date
        return date

    def save_action_memory(self):
        if len(self.df.Symbol.unique()) > 1:
            date_list = self.date_memory[:-1]
            df_date = pd.DataFrame(date_list)
            df_date.columns = ['Date']

            action_list = self.actions_memory
            df_actions = pd.DataFrame(action_list)
            df_actions.columns = self.data.Symbol.values
            df_actions.index = df_date.Date
        else:
            date_list = self.date_memory[:-1]
            action_list = self.actions_memory
            df_actions = pd.DataFrame(
                {'Date': date_list, 'Actions': action_list})
        return df_actions

    def _seed(self, seed=None):
        self.np_random, seed = seeding.np_random(seed)
        return [seed]
